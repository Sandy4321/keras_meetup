{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call me back\n",
    "\n",
    "... aka *keras callbacks* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides a powerfull mechanism for implementing callbacks, i.e., a function that must be called at a specific point of the training process. We can write our own callbacks (in an another meetup), or use some of the predefined keras callbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some data and define a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, MaxPool2D, Conv2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Prepare the data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape((-1, 28, 28, 1)) / 255.0\n",
    "x_test = x_test.reshape((-1, 28, 28, 1)) / 255.0\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (5, 5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some callbacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p models\n",
    "!mkdir -p logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "# Early Stopping automatically stops the training when a quantity has stopped improving\n",
    "# If you use the test set as the validation set, you are cheating!!!\n",
    "stopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=1, mode='min')\n",
    "\n",
    "# Save the model every 2 epochs!\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('models/weights.{epoch:02d}-{val_loss:.2f}.hdf5,', monitor='val_loss', verbose=1, save_best_only=False, \n",
    "                                             save_weights_only=False, period=2)\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1, batch_size=32, \n",
    "                                          write_graph=True, write_grads=True, write_images=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      " - 5s - loss: 0.2005 - acc: 0.9414 - val_loss: 0.0591 - val_acc: 0.9796\n",
      "Epoch 2/30\n",
      " - 4s - loss: 0.0443 - acc: 0.9863 - val_loss: 0.0354 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00002: saving model to models/weights.02-0.04.hdf5,\n",
      "Epoch 3/30\n",
      " - 4s - loss: 0.0307 - acc: 0.9906 - val_loss: 0.0266 - val_acc: 0.9915\n",
      "Epoch 4/30\n",
      " - 4s - loss: 0.0224 - acc: 0.9930 - val_loss: 0.0242 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00004: saving model to models/weights.04-0.02.hdf5,\n",
      "Epoch 5/30\n",
      " - 4s - loss: 0.0177 - acc: 0.9944 - val_loss: 0.0264 - val_acc: 0.9911\n",
      "Epoch 6/30\n",
      " - 4s - loss: 0.0143 - acc: 0.9953 - val_loss: 0.0250 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00006: saving model to models/weights.06-0.02.hdf5,\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(x_train, y_train, batch_size=256, epochs=30,\n",
    "          verbose=2, validation_data=(x_test, y_test), callbacks=[stopper, checkpoint, tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights.02-0.03.hdf5,  weights.04-0.02.hdf5,\r\n",
      "weights.02-0.04.hdf5,  weights.06-0.02.hdf5,\r\n"
     ]
    }
   ],
   "source": [
    "!ls models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the tensorboard!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "TensorBoard 1.5.1 at http://uranus:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](tensor1.png \"Title\")\n",
    "![alt text](tensor2.png \"Title\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
