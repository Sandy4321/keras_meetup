{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharing your models\n",
    "\n",
    "It is quite easy to save and share your models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a simple CNN for the MNIST:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.2116 - acc: 0.9370 - val_loss: 0.0544 - val_acc: 0.9828\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0502 - acc: 0.9846 - val_loss: 0.0435 - val_acc: 0.9860\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0323 - acc: 0.9898 - val_loss: 0.0314 - val_acc: 0.9895\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0229 - acc: 0.9927 - val_loss: 0.0273 - val_acc: 0.9908\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0178 - acc: 0.9941 - val_loss: 0.0333 - val_acc: 0.9889\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0144 - acc: 0.9955 - val_loss: 0.0258 - val_acc: 0.9918\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0122 - acc: 0.9961 - val_loss: 0.0340 - val_acc: 0.9902\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0112 - acc: 0.9964 - val_loss: 0.0356 - val_acc: 0.9906\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0073 - acc: 0.9977 - val_loss: 0.0346 - val_acc: 0.9908\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0071 - acc: 0.9977 - val_loss: 0.0305 - val_acc: 0.9922\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, MaxPool2D, Conv2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Prepare the data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape((-1, 28, 28, 1)) / 255.0\n",
    "x_test = x_test.reshape((-1, 28, 28, 1)) / 255.0\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (5, 5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(x_train, y_train,\n",
    "          batch_size=256,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 35us/step\n",
      "Train error (%):  0.10333333651225018\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "Test error (%):  0.7800000000000011\n"
     ]
    }
   ],
   "source": [
    "print(\"Train error (%): \", 100  - model.evaluate(x_train, y_train, batch_size=128)[1]*100)\n",
    "print(\"Test error (%): \", 100- model.evaluate(x_test, y_test, batch_size=128)[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model and its weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "a_new_fancy_model = load_model('my_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that everything still works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 128)         204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 733,706\n",
      "Trainable params: 733,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "a_new_fancy_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 35us/step\n",
      "Train error (%):  0.10333333651225018\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "Test error (%):  0.7800000000000011\n"
     ]
    }
   ],
   "source": [
    "print(\"Train error (%): \", 100  - a_new_fancy_model.evaluate(x_train, y_train, batch_size=128)[1]*100)\n",
    "print(\"Test error (%): \", 100 - a_new_fancy_model.evaluate(x_test, y_test, batch_size=128)[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*When sharing a model remember also to share the functions used for preprocessing the data!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
